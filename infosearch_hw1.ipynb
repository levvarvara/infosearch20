{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "infosearch_hw1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKu0tAZY0R9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "working_dir = r\"/content/fr-data\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLvs55R50i9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2df48c7d-f4c7-4120-ff83-22cf00e66097"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "import pymorphy2\n",
        "import string\n",
        "\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "def preprocessing(working_dir):\n",
        "  corpus = []\n",
        "\n",
        "  for root, dirs, files in os.walk(working_dir):\n",
        "    for name in files:\n",
        "      fpath = os.path.join(root, name)\n",
        "      with open(fpath, 'r') as f:  \n",
        "        text = word_tokenize(f.read())\n",
        "        text = [w.lower() for w in text]\n",
        "        table = str.maketrans('', '', string.punctuation)\n",
        "        text = [word for word in text if word.isalpha()]\n",
        "        text = [morph.parse(word)[0].normal_form for word in text]\n",
        "        corpus.append(' '.join(text))\n",
        "        \n",
        "  \n",
        "  return corpus\n",
        "        \n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8t0cmScJMA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e3f6bda7-7d68-41cb-cd52-650daac0e2ff"
      },
      "source": [
        "pip install pymorphy2[fast]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymorphy2[fast] in /usr/local/lib/python3.6/dist-packages (0.8)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (2.4.393442.3710985)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Requirement already satisfied: DAWG>=0.7.3; extra == \"fast\" in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBZthsPX1dmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = preprocessing(working_dir)\n",
        "#corpus[:10]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_H7SRn2OXw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "\n",
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdVfSVDmMzCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "#vectorizer.get_feature_names()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pqg64JNQ5Y2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix_freq = np.asarray(X.sum(axis=0)).ravel()\n",
        "final_matrix = np.array([np.array(vectorizer.get_feature_names()), matrix_freq])\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHhLW2gER0WM",
        "colab_type": "text"
      },
      "source": [
        "Берем список всех слов. Для каждого делаем в словаре список номеров документов, в кот. они встречаются. Дальше просто считаем количество элементов и"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sp83H4oSknD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "38f7cdfe-12e7-4fad-c8fc-8384e10a073c"
      },
      "source": [
        "msw = ''\n",
        "freq_s = 0\n",
        "freq_l = 100\n",
        "mlw = ''\n",
        "words = vectorizer.get_feature_names()\n",
        "\n",
        "for word in words:\n",
        "  ind = vectorizer.vocabulary_.get(word)\n",
        "  if ind > freq_s:\n",
        "    msw = word\n",
        "    freq_s = ind\n",
        "  if ind < freq_l:\n",
        "    mlw = word\n",
        "    freq_l = ind\n",
        "\n",
        "print(\"{}: {}\".format(msw, freq_s))\n",
        "print(\"{}: {}\".format(mlw, freq_l))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ёще: 14554\n",
            "after: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttBf7B382ZNX",
        "colab_type": "text"
      },
      "source": [
        "**Ответ на вопрос 1:** *ещё* (индекс 14554)\n",
        "**Ответ на вопрос 2:** *after* (индекс 0, первое по списку, вероятно)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4mDPK8X2rnA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b3db7ddc-5567-4b08-cc57-6c10cf9cc89e"
      },
      "source": [
        "char_names = [\"моника\", \"рэйчел\", \"чендлер\", \"росс\", \"фиби\", \"джоу\"]\n",
        "\n",
        "mpn = ''\n",
        "freq = 0\n",
        "\n",
        "for name in char_names:\n",
        "  ind = vectorizer.vocabulary_.get(name)\n",
        "  if ind > freq:\n",
        "    mpn = name\n",
        "    freq = ind\n",
        "    print(\"{}: {}\".format(mpn, freq))\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "моника: 5873\n",
            "рэйчел: 10982\n",
            "чендлер: 13933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGiMUFPv6kzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "original_df = pd.DataFrame(final_matrix)\n",
        "original_df.to_pickle(\"./fr_data.pkl\")"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N6uezP76mYh",
        "colab_type": "text"
      },
      "source": [
        "**Ответ на вопрос 4:** Чендлер (индекс 13933)"
      ]
    }
  ]
}